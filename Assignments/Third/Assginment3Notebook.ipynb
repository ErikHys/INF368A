{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Assignments.Third.Model import MyFFLM, cross_entropy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "with open(\"lotrFotr.txt\",\"r\",encoding='utf-8') as file:\n",
    "    raw_txt = file.read()\n",
    "\n",
    "stripped_txt_lotr = raw_txt.replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ')\\\n",
    "    .replace(';', '').replace(':', '').replace('  ', ' ').replace('.', '').replace(',', '').replace('\"', '').lower()\n",
    "stripped_txt_lotr = re.sub(r'[^\\w\\s]', '', stripped_txt_lotr).split()\n",
    "\n",
    "with open(\"mobydick.txt\",\"r\",encoding='utf-8') as file:\n",
    "    raw_txt = file.read()\n",
    "\n",
    "stripped_txt_mb = raw_txt.replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ')\\\n",
    "    .replace(';', '').replace(':', '').replace('  ', ' ').replace('.', '').replace(',', '').lower().split()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9794\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(stripped_txt_lotr))\n",
    "vocab.sort()\n",
    "vocab_dict = {}\n",
    "for i, word in enumerate(vocab):\n",
    "    identity_vector = np.zeros(len(vocab))\n",
    "    identity_vector[i] = 1\n",
    "    vocab_dict[word] = identity_vector\n",
    "print(len(vocab))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "# Need to split up bc of ram issues, batches is the answer I think\n",
    "memory_depth = 3\n",
    "dataX = np.zeros((len(stripped_txt_lotr[:1000]) - memory_depth, memory_depth, len(vocab_dict)))\n",
    "dataY = np.zeros(len(stripped_txt_lotr[:1000]) - memory_depth, dtype='int32')\n",
    "for i in range(len(stripped_txt_lotr[:1000]) - memory_depth):\n",
    "    x = np.zeros((memory_depth, len(vocab_dict)))\n",
    "    for j in range(memory_depth):\n",
    "        x[j] = vocab_dict[stripped_txt_lotr[:1000][i+j]]\n",
    "    dataX[i] = x\n",
    "    dataY[i] = np.argmax(vocab_dict[stripped_txt_lotr[:1000][i+memory_depth]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "rings\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "for\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "the\n",
      "8463\n"
     ]
    }
   ],
   "source": [
    "reversed_dict = {}\n",
    "for key in vocab_dict:\n",
    "    reversed_dict[np.argmax(vocab_dict[key])] = key\n",
    "for x in dataX[0]:\n",
    "    print(reversed_dict[np.argmax(x)])\n",
    "    print(x)\n",
    "print(reversed_dict[dataY[0]])\n",
    "print(dataY[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 batch: 0/187\n",
      "loss: [[nan nan nan ... nan nan nan]] nan\n",
      "Predicted vs actual: irresistibly elvenkings\n",
      "Predicted value: 1.0\n",
      "epoch: 0 batch: 1/187\n",
      "loss: [[-1.38643102e-04 -1.53277723e-04 -1.11616147e-04 ... -1.35855697e-04\n",
      "  -7.46994364e-05 -6.24829444e-05]] 9.483912174747084\n",
      "Predicted vs actual: hills under\n",
      "Predicted value: 0.00016113631903191973\n",
      "epoch: 0 batch: 2/187\n",
      "loss: [[-1.38644788e-04 -1.53277397e-04 -1.11616033e-04 ... -1.35855477e-04\n",
      "  -7.46994111e-05 -6.24829336e-05]] 9.35862352015115\n",
      "Predicted vs actual: hills the\n",
      "Predicted value: 0.00016113593688307475\n"
     ]
    }
   ],
   "source": [
    "v_len = len(vocab)\n",
    "data_set_length = len(stripped_txt_lotr) - memory_depth\n",
    "batch_size = 1000\n",
    "model = MyFFLM(v_len, 64, learning_rate=0.001, memory_depth=memory_depth)\n",
    "# loss = 0\n",
    "for epoch in range(60):\n",
    "    for batch in range(data_set_length // batch_size):\n",
    "        dataX = np.zeros((batch_size - memory_depth, memory_depth, len(vocab_dict)))\n",
    "        dataY = np.zeros(batch_size - memory_depth, dtype='int32')\n",
    "        for i in range(batch_size - memory_depth):\n",
    "            x = np.zeros((memory_depth, len(vocab_dict)))\n",
    "            for j in range(memory_depth):\n",
    "                x[j] = vocab_dict[stripped_txt_lotr[batch:batch+batch_size][i+j]]\n",
    "            dataX[i] = x\n",
    "            dataY[i] = np.argmax(vocab_dict[stripped_txt_lotr[batch:batch+batch_size][i+memory_depth]])\n",
    "        for k, (x, y) in enumerate(zip(dataX, dataY)):\n",
    "            # print(k, x, y)\n",
    "            y_t = np.zeros(v_len)\n",
    "            y_t[y] = 1\n",
    "            # print(y_t, np.argmax(y_t))\n",
    "            y_pred = model.forward(x)\n",
    "            # loss += 0.01 * (cross_entropy(y_t, y_pred) - loss)\n",
    "            model.backprop(y_t, y_pred)\n",
    "            if k % 998 == 1:\n",
    "                print(\"epoch:\", epoch, \"batch:\", f\"{batch}/{data_set_length//batch_size}\")\n",
    "                l = cross_entropy(y_t, y_pred)\n",
    "                print(\"loss:\", l, l[0, np.argmax(l)])\n",
    "                print(\"Predicted vs actual:\", reversed_dict[np.argmax(y_pred)], reversed_dict[y])\n",
    "                print(\"Predicted value:\", y_pred[0, np.argmax(y_pred)])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}