{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "with open(\"lotrFotr.txt\",\"r\",encoding='utf-8') as file:\n",
    "    raw_txt = file.read()\n",
    "\n",
    "stripped_txt_lotr = raw_txt.replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ')\\\n",
    "    .replace(';', '').replace(':', '').replace('  ', ' ').replace('.', '').replace(',', '').lower().split()\n",
    "\n",
    "with open(\"mobydick.txt\",\"r\",encoding='utf-8') as file:\n",
    "    raw_txt = file.read()\n",
    "\n",
    "stripped_txt_mb = raw_txt.replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ')\\\n",
    "    .replace(';', '').replace(':', '').replace('  ', ' ').replace('.', '').replace(',', '').lower().split()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "vocab = list(set(stripped_txt_lotr))\n",
    "vocab.sort()\n",
    "vocab_dict = {}\n",
    "for i, word in enumerate(vocab):\n",
    "    identity_vector = np.zeros(len(vocab))\n",
    "    identity_vector[i] = 1\n",
    "    vocab_dict[word] = identity_vector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 53.6 GiB for an array with shape (187732, 3, 12775) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-16-adec18a79b9b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Need to split up bc of ram issues, batches is the answer I think\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mmemory_depth\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mdataX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstripped_txt_lotr\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mmemory_depth\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmemory_depth\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvocab_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mdataY\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstripped_txt_lotr\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mmemory_depth\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstripped_txt_lotr\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mmemory_depth\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 53.6 GiB for an array with shape (187732, 3, 12775) and data type float64"
     ]
    }
   ],
   "source": [
    "# Need to split up bc of ram issues, batches is the answer I think\n",
    "memory_depth = 3\n",
    "dataX = np.zeros((len(stripped_txt_lotr[:1000]) - memory_depth, memory_depth, len(vocab_dict)))\n",
    "dataY = np.zeros(len(stripped_txt_lotr[:1000]) - memory_depth)\n",
    "for i in range(len(stripped_txt_lotr[:1000]) - memory_depth):\n",
    "    x = np.zeros((memory_depth, len(vocab_dict)))\n",
    "    for j in range(memory_depth):\n",
    "        x[j] = vocab_dict[stripped_txt_lotr[:1000][i+j]]\n",
    "    dataX[i] = x\n",
    "    dataY[i] = np.argmax(vocab_dict[stripped_txt_lotr[:1000][i+memory_depth]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reversed_dict = {}\n",
    "for key in vocab_dict:\n",
    "    reversed_dict[np.argmax(vocab_dict[key])] = key\n",
    "for x in dataX[0]:\n",
    "    print(reversed_dict[np.argmax(x)])\n",
    "    print(x)\n",
    "print(reversed_dict[dataY[0]])\n",
    "print(dataY[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}