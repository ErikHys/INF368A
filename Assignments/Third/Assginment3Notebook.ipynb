{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Assignments.Third.Model import MyFFLM, cross_entropy\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Read data\n",
    "with open(\"lotrFotr.txt\",\"r\",encoding='utf-8') as file:\n",
    "    raw_txt = file.read()\n",
    "\n",
    "\n",
    "stripped_txt_lotr = raw_txt.replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ')\\\n",
    "    .replace(';', '').replace(':', '').replace('  ', ' ').replace('.', '').replace(',', '').replace('\"', '').lower()\n",
    "stripped_txt_lotr = re.sub(r'[^\\w\\s]', '', stripped_txt_lotr).split()\n",
    "stripped_txt_lotr = stripped_txt_lotr[:len(stripped_txt_lotr)//50]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  1136\n"
     ]
    }
   ],
   "source": [
    "# Create  vocabulary\n",
    "vocab = list(set(stripped_txt_lotr))\n",
    "vocab.sort()\n",
    "vocab_dict = {}\n",
    "for i, word in enumerate(vocab):\n",
    "    identity_vector = np.zeros(len(vocab))\n",
    "    identity_vector[i] = 1\n",
    "    vocab_dict[word] = identity_vector\n",
    "print(\"Vocab size: \", len(vocab))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set size: 3738\n"
     ]
    }
   ],
   "source": [
    "# create labels and dataset\n",
    "memory_depth = 5\n",
    "dataX = np.zeros((len(stripped_txt_lotr) - memory_depth, memory_depth, len(vocab_dict)), dtype='float32')\n",
    "dataY = np.zeros((len(stripped_txt_lotr) - memory_depth, len(vocab_dict)), dtype='int16')\n",
    "for i in range(len(stripped_txt_lotr) - memory_depth):\n",
    "    x = np.zeros((memory_depth, len(vocab_dict)))\n",
    "    for j in range(memory_depth):\n",
    "        x[j] = vocab_dict[stripped_txt_lotr[i+j]]\n",
    "    dataX[i] = x\n",
    "    dataY[i] = vocab_dict[stripped_txt_lotr[i+memory_depth]]\n",
    "print(\"Data set size:\", dataX.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "rings\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "for\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "the\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "elvenkings\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "under\n",
      "[0 0 0 ... 0 0 0] 1055\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to reverse the one hot encoding\n",
    "reversed_dict = {}\n",
    "for key in vocab_dict:\n",
    "    reversed_dict[np.argmax(vocab_dict[key])] = key\n",
    "for x in dataX[0]:\n",
    "    print(reversed_dict[np.argmax(x)])\n",
    "    print(x)\n",
    "print(reversed_dict[np.argmax(dataY[0])])\n",
    "print(dataY[0], np.argmax(dataY[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length: 2990 Test set length: 748\n"
     ]
    }
   ],
   "source": [
    "# Shuffle and split\n",
    "perm = np.random.permutation(dataX.shape[0])\n",
    "shuffledX = dataX[perm]\n",
    "shuffledY = dataY[perm]\n",
    "trainX, testX = shuffledX[:int(dataX.shape[0]*0.80)], shuffledX[int(dataX.shape[0]*0.80):]\n",
    "trainY, testY = shuffledY[:int(dataX.shape[0]*0.80)], shuffledY[int(dataX.shape[0]*0.80):]\n",
    "print(\"Train set length:\", trainX.shape[0], \"Test set length:\", testX.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch progression 1/20, loss: 7.483842637761003, accuracy: 0.008319467554076539:  21%|██        | 627/2990 [00:17<00:43, 54.34it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-32-e92b466f40e3>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrainX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrainY\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m         \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackprop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m0.005\u001B[0m\u001B[1;33m*\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcross_entropy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\INF368A\\Assignments\\Third\\Model.py\u001B[0m in \u001B[0;36mbackprop\u001B[1;34m(self, y_true, y_pred, dloss)\u001B[0m\n\u001B[0;32m    105\u001B[0m         \u001B[0md\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdelta\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mq\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmemory_depth\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmemory_depth\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membedding_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    106\u001B[0m         \u001B[0mdl_da0\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0md\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 107\u001B[1;33m         \u001B[0mdl_dz0\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdl_da0\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'-1'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmemory_depth\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    108\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    109\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdL_dw\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'2'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mscale\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdl_dz2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Set up model\n",
    "v_len = len(vocab)\n",
    "data_set_length = len(stripped_txt_lotr) - memory_depth\n",
    "model = MyFFLM(v_len, 128, learning_rate=0.01, memory_depth=memory_depth)\n",
    "\n",
    "# Set up training\n",
    "loss = 0\n",
    "epochs = 20\n",
    "\n",
    "# Do training\n",
    "for epoch in range(epochs):\n",
    "    epoch_progress = tqdm(total=trainX.shape[0], desc=\"epoch progression {}/{}, loss: {}, accuracy: 0\".format(epoch+1, epochs, loss))\n",
    "    loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    for k, (x, y) in enumerate(zip(trainX, trainY)):\n",
    "        y_pred = model.forward(x)\n",
    "        model.backprop(y)\n",
    "        # Exponentially weighted average loss\n",
    "        loss += 0.005*(cross_entropy(y, y_pred) - loss)\n",
    "        if y[np.argmax(y_pred)] == 1:\n",
    "            epoch_accuracy += 1\n",
    "        # This is just to update the progressbar every 100 case\n",
    "        if k % 100 == 0:\n",
    "            epoch_progress.set_description(desc=\"epoch progression {}/{}, loss: {}, accuracy: {}\".format(epoch+1, epochs, loss, epoch_accuracy/(k+1)), refresh=True)\n",
    "        epoch_progress.update()\n",
    "    epoch_progress.close()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# See results with test set\n",
    "acc = 0\n",
    "print(\"Predicted, true, predicted value\")\n",
    "for x, y in zip(testX[:30], testY[:30]):\n",
    "\n",
    "    print(reversed_dict[np.argmax(model.forward(x))], reversed_dict[np.argmax(y)], model.forward(x).max())\n",
    "    if reversed_dict[np.argmax(model.forward(x))] == reversed_dict[np.argmax(y)]:\n",
    "        acc += 1\n",
    "print(\"Test accuracy:\", acc/testX.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save embeddings for projector\n",
    "out_v = \"\"\n",
    "out_m = \"\"\n",
    "weights = model.embedding_layer.weights\n",
    "for index, word in enumerate(vocab):\n",
    "  vec = weights[:, index]\n",
    "  out_v = out_v + ('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m = out_m +  (word + \"\\n\")\n",
    "\n",
    "with open(\"mbVec.tsv\", 'w', encoding='utf-8') as file:\n",
    "    file.write(out_v)\n",
    "with open(\"mbMeta.tsv\", 'w', encoding='utf-8') as file:\n",
    "    file.write(out_m)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}