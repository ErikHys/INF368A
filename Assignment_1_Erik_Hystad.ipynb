{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Assignment 1 Erik Hystad\n",
    "\n",
    "Requirements:\n",
    "Nltk\n",
    "    * Corpus.Brown\n",
    "    * Corpus.Wordnet\n",
    "    * Collocations\n",
    "Jupyter Notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.collocations import *\n",
    "from nltk.corpus import wordnet\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " ### Task 1.1\n",
    "First I will load the corpus and find all collocations with the BigramCollocationFinder."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "corpus = brown.words()\n",
    "\n",
    "finder = BigramCollocationFinder.from_words(corpus)\n",
    "collocations = finder.nbest(bigram_measures.pmi, 10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Task 1.1.1\n",
    "Then I will apply a frequency filter to the finder, which I here set to 6, to remove any collocations that\n",
    "appear less than 6 times. I chose 6 to reduce somewhat the time the hypothesis testing in 1.1.2 would take to run.\n",
    "Then I only keep collocations that are made up of nouns and adjectives.\n",
    "\n",
    "After that I write these to a file, '1.1.1.txt'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "finder.apply_freq_filter(10)\n",
    "frequency_collocations = finder.nbest(bigram_measures.pmi, 10000)\n",
    "\n",
    "\n",
    "tagged = [nltk.pos_tag(bigram) for bigram in frequency_collocations]\n",
    "including = ['NN', 'JJ']\n",
    "\n",
    "\n",
    "# A function to see if a word is nouns or adjectives, will include NNS etc...\n",
    "def check(bigram):\n",
    "    for _, cl in bigram:\n",
    "        result = False\n",
    "        for cls in including:\n",
    "            if cls in cl:\n",
    "                result = True\n",
    "        if not result:\n",
    "            return result\n",
    "    return True\n",
    "\n",
    "\n",
    "noun_and_adjectives_collocations = [bigram for bigram in tagged if check(bigram)]\n",
    "\n",
    "with open(\"1_1_1.txt\", 'w') as file:\n",
    "    for bigram in noun_and_adjectives_collocations:\n",
    "        file.write(bigram[0][0] + ' ' + bigram[1][0] + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Task 1.1.2\n",
    "\n",
    "Here I did hypothesis testing on the remaining bigrams, the ones already filtered by nouns, adjectives and more than\n",
    "10 occurrences.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = len(corpus)\n",
    "\n",
    "\n",
    "def hypothesis_test(collocation, confidence=2.576):\n",
    "    first, second = collocation\n",
    "    sample_mean = (finder.ngram_fd[collocation] / n)\n",
    "    mean_of_the_dist = ((corpus.count(first) / n) * (corpus.count(second) / n))\n",
    "    t = (sample_mean - mean_of_the_dist) / (math.sqrt((sample_mean * (1 - sample_mean))**2/n))\n",
    "    return t > confidence\n",
    "\n",
    "with open(\"1_1_2.txt\", 'w') as file:\n",
    "    ts = []\n",
    "    pbar = tqdm(total=len(noun_and_adjectives_collocations), desc='Hypothesis test')\n",
    "    for bigram in noun_and_adjectives_collocations:\n",
    "        if hypothesis_test((bigram[0][0], bigram[1][0])):\n",
    "            file.write(bigram[0][0] + ' ' + bigram[1][0] + '\\n')\n",
    "        pbar.update()\n",
    "    pbar.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('1_1_2.txt', 'r') as file:\n",
    "    raw = file.read()\n",
    "\n",
    "learned_collocations = [(x.split()[0].lower(), x.split()[1].lower()) for x in raw.split('\\n') if x != '']\n",
    "learned_collocations_firsts = set([x[0] for x in learned_collocations])\n",
    "learned_collocations_seconds = set([x[1] for x in learned_collocations])\n",
    "\n",
    "\n",
    "def correction_tool(first, second):\n",
    "    for synset in wordnet.synsets(first):\n",
    "        for synonym in synset.lemmas():\n",
    "            f_synonym = synonym.name()\n",
    "            if f_synonym in learned_collocations_firsts:\n",
    "                second_learned = [x[1] for x in learned_collocations if x[0] == f_synonym]\n",
    "                for s in second_learned:\n",
    "                    for second_synset in wordnet.synsets(second):\n",
    "                        for second_synonym in second_synset.lemmas():\n",
    "                            s_synonym = second_synonym.name()\n",
    "                            if s == s_synonym and first + ' ' + second != f_synonym + ' ' + s:\n",
    "                                print('Changed', first + ' ' + second, 'to', f_synonym + ' ' + s, '!')\n",
    "                                return f_synonym + ' ' + s\n",
    "    print(\"Found no matching collocation.\")\n",
    "\n",
    "first, second = input(\"Write bigram to see if can be corrected to a collocation.\")\n",
    "correction_tool(first, second)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}